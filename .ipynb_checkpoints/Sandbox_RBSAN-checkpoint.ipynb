{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59787510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1857d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Month Project ID    Project Name                 User Job Type  Job ID  \\\n",
      "0  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic  jGhHhb   \n",
      "1  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic  tSsLeb   \n",
      "2  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic   DMTgU   \n",
      "3  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic   zBTgU   \n",
      "4  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic   OMTgU   \n",
      "5  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic   endmU   \n",
      "6  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic   FrTNm   \n",
      "7  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic   owujb   \n",
      "8  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic   swexp   \n",
      "9  2023-04      UgQWc  Welding_ABAQUS  dohyunko@hanwha.com    Basic   VgpBp   \n",
      "\n",
      "                                            Job Name Software  \\\n",
      "0                                           작업 제목 없음   Abaqus   \n",
      "1                 [H3306 weld sequence] HT_cut_start   Abaqus   \n",
      "2        [H3306 weld sequence] HT_cut_start_RES(G32)   Abaqus   \n",
      "3  [H3306 weld sequence] HT_cut_start_RES(G32) (C...   Abaqus   \n",
      "4        [H3306 weld sequence] HT_cut_start_RES(2G3)   Abaqus   \n",
      "5                                       Untitled Job   Abaqus   \n",
      "6                                     [H3306]HT_Ncut   Abaqus   \n",
      "7                                 [H3306] EP_CUT_2G3   Abaqus   \n",
      "8                            [H3306] EP_CUT_2G3 (복제)   Abaqus   \n",
      "9                            [H3306] EP_CUT_2G3 (복제)   Abaqus   \n",
      "\n",
      "  Rescale On-Demand License    Coretype Billing Priority  Cores  Unit Hours  \\\n",
      "0                     False    Starlite              ODP    1.0     0.16000   \n",
      "1                     False    Starlite              ODP   16.0     5.45778   \n",
      "2                     False    Starlite              ODP   16.0     3.05778   \n",
      "3                     False    Starlite              ODP   16.0     1.45778   \n",
      "4                     False    Starlite              ODP   16.0     1.97778   \n",
      "5                     False    Starlite              ODP   16.0   147.84000   \n",
      "6                     False  Calcite v2              ODE   16.0   158.09778   \n",
      "7                     False  Calcite v2              ODE   16.0    16.07112   \n",
      "8                     False  Calcite v2              ODE   16.0     1.42223   \n",
      "9                     False  Calcite v2              ODE   16.0     1.47556   \n",
      "\n",
      "   Charge  \n",
      "0    0.02  \n",
      "1    0.53  \n",
      "2    0.30  \n",
      "3    0.15  \n",
      "4    0.20  \n",
      "5   14.32  \n",
      "6   10.27  \n",
      "7    1.05  \n",
      "8    0.10  \n",
      "9    0.07  \n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"billing_08-246800072_2023_03-2023_06.csv\")\n",
    "df_raw = df_raw.drop([\"Workspace ID\", \"License Settings\", \"SKU\"], axis=1)\n",
    "df_compute = df_raw[df_raw[\"Type\"] == 'Compute'].reset_index(drop=True)\n",
    "df_compute = df_compute.drop([\"Type\",\"Submit Date\", \"Start Date\", \"Stop Date\", \"Unit Charge/Hour\", \"Walltime\"], axis=1)\n",
    "df_compute['Coretype'] = df_compute['Description'].str.extract(r':\\s(.*)')\n",
    "df_compute['Charge'] = df_compute['Charge'].str.replace(\"$\", \"\")\n",
    "df_compute['Charge'] = df_compute['Charge'].astype(float)\n",
    "df_compute = df_compute.drop([\"Description\"], axis=1)\n",
    "column_order = [\"Month\", \"Project ID\", \"Project Name\", \"User\", \"Job Type\", \"ID\", \"Name\",\n",
    "                \"Software\", \"Rescale On-Demand License\",\n",
    "                \"Coretype\", \"Billing Priority\", \"Cores\", \"Unit Hours\", \"Charge\"]\n",
    "df_compute = df_compute[column_order]\n",
    "df_compute.columns = [\"Month\", \"Project ID\", \"Project Name\", \"User\", \"Job Type\", \"Job ID\", \"Job Name\",\n",
    "                      \"Software\", \"Rescale On-Demand License\",\n",
    "                      \"Coretype\", \"Billing Priority\", \"Cores\", \"Unit Hours\", \"Charge\"]\n",
    "print(df_compute.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab234b4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the apiconfig file is done\n",
      "131\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Get the list of ouputs from Meshing job\\nurl_jobs = apibaseurl + '/api/v2/jobs/'\\ncurrent_page = 1\\nlast_page = False\\n# Make the dictionary of outputs(This block is suitable for less than 20 files because this is meshing job)\\nwhile (not(last_page)):\\n    check_outputfile = requests.get(\\n        url_jobs,\\n        headers = {'Authorization': token},\\n        params = {'page' : current_page}\\n        )\\n    check_outputfile_dict = json.loads(check_outputfile.text)\\n    count = check_outputfile_dict['count']\\n# If the number of files is less than 10\\n    if current_page == 1:\\n        outputfileid = [0 for i in range(count)]\\n        outputfilename = [0 for i in range(count)]\\n        for i in range(0, count):\\n            outputfileid[i] = check_outputfile_dict['results'][i]['id']\\n            outputfilename[i] = check_outputfile_dict['results'][i]['name']\\n# If the number of files is larger/equal than 10\\n    elif count > current_page * 10:\\n        indexup = (current_page - 1) * 10\\n        for i in range(0, 10):\\n            outputfileid[i + indexup] = check_outputfile_dict['results'][i]['id']\\n            outputfilename[i + indexup] = check_outputfile_dict['results'][i]['name']\\n    else:\\n        indexup = (current_page - 1) * 10\\n        uplimit = count % indexup\\n        for i in range(0, uplimit):\\n            outputfileid[i + indexup] = check_outputfile_dict['results'][i]['id']\\n            outputfilename[i + indexup] = check_outputfile_dict['results'][i]['name']\\n# If the number of files is larger/equal than 10, go to the next page for getting a information of files\\n    if (check_outputfile_dict['next'] == None):\\n        last_page = True\\n    else:\\n        current_page += 1\\n# Save a name of outputs and ID to dictionary\\noutputfileinfo = dict(zip(outputfilename, outputfileid))\\nfileextensionlist = ['.tar']\\nfor j in fileextensionlist:\\n    search = j\\n    for k in outputfileinfo.keys():\\n        if search in k:\\n            fileid_tar = outputfileinfo.get(k)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "home_path = os.path.expanduser(\"~\")\n",
    "apiconfig = home_path + '/' + '.config' + '/' + 'rescale' + '/' + 'apiconfig'\n",
    "if (os.path.isfile(apiconfig)):\n",
    "    f = open(apiconfig, \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    apibaseurl = lines[1].split(\"=\")[1].rstrip('\\n').lstrip().replace(\"'\",\"\")\n",
    "    apikey = lines[2].split(\"=\")[1].rstrip('\\n').lstrip().replace(\"'\",\"\")\n",
    "    token = 'Token ' + apikey\n",
    "    print('Reading the apiconfig file is done')\n",
    "\n",
    "\n",
    "current_page = 1\n",
    "last_page = False\n",
    "list_jobid = []\n",
    "\n",
    "precheck_count = requests.get(\n",
    "    apibaseurl + '/api/v2/jobs/',\n",
    "    headers = {'Authorization': token}\n",
    ")\n",
    "\n",
    "precheck_count_dict = json.loads(precheck_count.text)\n",
    "count = req_dict['count']\n",
    "npages = (int(count) // 10) + 2\n",
    "\n",
    "for i in range(1, npages):\n",
    "    for j in range(0, 10):\n",
    "        list_jobid.append(p)\n",
    "\n",
    "#while (not(last_page)):\n",
    "    \n",
    "#    if current_page == 1:\n",
    "        \n",
    "\n",
    "#req_dict = json.loads(req.text)\n",
    "#data = json.dumps(req_dict, indent=4)\n",
    "#print(data)\n",
    "\n",
    "#with open('./test', 'w') as file:\n",
    "#    file.write(data)\n",
    "\n",
    "#print(\"Dictionary saved\")\n",
    "\n",
    "'''\n",
    "# Get the list of ouputs from Meshing job\n",
    "url_jobs = apibaseurl + '/api/v2/jobs/'\n",
    "current_page = 1\n",
    "last_page = False\n",
    "# Make the dictionary of outputs(This block is suitable for less than 20 files because this is meshing job)\n",
    "while (not(last_page)):\n",
    "    check_outputfile = requests.get(\n",
    "        url_jobs,\n",
    "        headers = {'Authorization': token},\n",
    "        params = {'page' : current_page}\n",
    "        )\n",
    "    check_outputfile_dict = json.loads(check_outputfile.text)\n",
    "    count = check_outputfile_dict['count']\n",
    "# If the number of files is less than 10\n",
    "    if current_page == 1:\n",
    "        outputfileid = [0 for i in range(count)]\n",
    "        outputfilename = [0 for i in range(count)]\n",
    "        for i in range(0, count):\n",
    "            outputfileid[i] = check_outputfile_dict['results'][i]['id']\n",
    "            outputfilename[i] = check_outputfile_dict['results'][i]['name']\n",
    "# If the number of files is larger/equal than 10\n",
    "    elif count > current_page * 10:\n",
    "        indexup = (current_page - 1) * 10\n",
    "        for i in range(0, 10):\n",
    "            outputfileid[i + indexup] = check_outputfile_dict['results'][i]['id']\n",
    "            outputfilename[i + indexup] = check_outputfile_dict['results'][i]['name']\n",
    "    else:\n",
    "        indexup = (current_page - 1) * 10\n",
    "        uplimit = count % indexup\n",
    "        for i in range(0, uplimit):\n",
    "            outputfileid[i + indexup] = check_outputfile_dict['results'][i]['id']\n",
    "            outputfilename[i + indexup] = check_outputfile_dict['results'][i]['name']\n",
    "# If the number of files is larger/equal than 10, go to the next page for getting a information of files\n",
    "    if (check_outputfile_dict['next'] == None):\n",
    "        last_page = True\n",
    "    else:\n",
    "        current_page += 1\n",
    "# Save a name of outputs and ID to dictionary\n",
    "outputfileinfo = dict(zip(outputfilename, outputfileid))\n",
    "fileextensionlist = ['.tar']\n",
    "for j in fileextensionlist:\n",
    "    search = j\n",
    "    for k in outputfileinfo.keys():\n",
    "        if search in k:\n",
    "            fileid_tar = outputfileinfo.get(k)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354ee137",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"qCJPd\",\n",
      "  \"isLowPriority\": true,\n",
      "  \"billingPriorityValue\": \"ON_DEMAND\",\n",
      "  \"name\": \"STAR-CCM+ with Checkpoint Restart\",\n",
      "  \"description\": \"Refer to the Checkpoint Restart for STAR-CCM+ with Rescale CpR tile\",\n",
      "  \"suspensionStatus\": null,\n",
      "  \"suspendAvailable\": null,\n",
      "  \"elapsedWalltimeSeconds\": 0,\n",
      "  \"owner\": \"junghoon+test@rescale.com\",\n",
      "  \"clonedFrom\": \"xdZfd\",\n",
      "  \"templatedFrom\": null,\n",
      "  \"resourceFilters\": [],\n",
      "  \"archiveFilters\": [],\n",
      "  \"isTemplate\": true,\n",
      "  \"cidrRule\": \"0.0.0.0/0\",\n",
      "  \"publicKey\": \"ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQEAlhzCjkRYxSa0HZunyPZoIDPgNqV2/TD7apUBda0GfIGV5Ebj7DFA205/w1qeiMqsO8lu0s7o4d7XU5133hw2FvUDOc8IjzsGDhUnMjaA/VhhwWxGX/74mMlvParW0o6w/eMlzSOgHtHcu0p1HcC2nn6a3EIRD/l83DXjl2+RPyfW0lV8x6lE52tPbpq5/GAU/YEmvJJ4Kmqi4Y387wdnYcsldOIPgBqdcMBlgmEyEzbjNLpg8xtXxit/DbmRX4bD+hBo6HaWCyIut7Cn6eh2DP0cTlHeOTDz5bBft60biCIjH32Hg+f52DotT9Ht9AyU0toUEoV4IJZ8XWANLZ9yXw== rsa-key-20210506\",\n",
      "  \"sshPort\": 22,\n",
      "  \"dateInserted\": \"2023-07-08T06:29:45.724092Z\",\n",
      "  \"sharedWith\": [],\n",
      "  \"isPinned\": null,\n",
      "  \"userTags\": [\n",
      "    {\n",
      "      \"name\": \"Template\",\n",
      "      \"normalizedName\": \"template\"\n",
      "    }\n",
      "  ],\n",
      "  \"jobanalyses\": [\n",
      "    {\n",
      "      \"envVars\": {\n",
      "        \"LM_PROJECT\": \"DObwqwCBU/pij8v2eXAoZw\",\n",
      "        \"CDLMD_LICENSE_FILE\": \"1999@flex.cd-adapco.com\"\n",
      "      },\n",
      "      \"useRescaleLicense\": false,\n",
      "      \"onDemandLicenseSeller\": null,\n",
      "      \"userDefinedLicenseSettings\": null,\n",
      "      \"analysis\": {\n",
      "        \"code\": \"cd_adapco_star_ccm\",\n",
      "        \"name\": \"Simcenter STAR-CCM+\",\n",
      "        \"version\": \"15.06.008\",\n",
      "        \"versionName\": \"15.06.008 (Mixed Precision)\",\n",
      "        \"thumbnail\": \"https://d1jkc2r02szfl4.cloudfront.net/static/img/analyses_images/cd_adapco_star_ccm/siemens-tech-partner_9AVvohw.png\",\n",
      "        \"type\": \"compute\",\n",
      "        \"osFamily\": \"linux\"\n",
      "      },\n",
      "      \"command\": \"\",\n",
      "      \"flags\": {\n",
      "        \"igCv\": true\n",
      "      },\n",
      "      \"hardware\": {\n",
      "        \"slots\": 1,\n",
      "        \"coresPerSlot\": 32,\n",
      "        \"coreType\": \"calcite\",\n",
      "        \"coreSummary\": {\n",
      "          \"numberOfNodes\": 1.0,\n",
      "          \"memoryPerNode\": 256000.0,\n",
      "          \"storagePerNode\": 2400,\n",
      "          \"gpusPerNode\": 0\n",
      "        },\n",
      "        \"walltime\": 10,\n",
      "        \"coreClass\": null,\n",
      "        \"type\": \"compute\",\n",
      "        \"scheduler\": {},\n",
      "        \"rceConnector\": {},\n",
      "        \"isReusable\": false\n",
      "      },\n",
      "      \"inputFolders\": [],\n",
      "      \"postProcessScript\": null,\n",
      "      \"postProcessScriptCommand\": \"\",\n",
      "      \"preProcessScript\": null,\n",
      "      \"preProcessScriptCommand\": \"\",\n",
      "      \"templateTasks\": [],\n",
      "      \"inputFiles\": []\n",
      "    },\n",
      "    {\n",
      "      \"envVars\": {},\n",
      "      \"useRescaleLicense\": false,\n",
      "      \"onDemandLicenseSeller\": null,\n",
      "      \"userDefinedLicenseSettings\": null,\n",
      "      \"analysis\": {\n",
      "        \"code\": \"rescale-ckpt\",\n",
      "        \"name\": \"Rescale Checkpoint Restart\",\n",
      "        \"version\": \"rescale_ckpt_1\",\n",
      "        \"versionName\": \"1.0\",\n",
      "        \"thumbnail\": \"https://d1jkc2r02szfl4.cloudfront.net/static/img/analyses_images/rescale-ckpt/rescale_s1QHFHN.png\",\n",
      "        \"type\": \"compute\",\n",
      "        \"osFamily\": \"linux\"\n",
      "      },\n",
      "      \"command\": \"### Please attach this as second tile only. Do not include any run commands in the first tile\\n\\n### Specify RESTART_FILE with appropriate regex\\nexport RESTART_FILE='CpR_Reference_AutoSave@[0-9]*.sim'\\n\\n### Information to be saved at the time of archive creation. Variables prepended with \\\"#RESCALE_CPR_\\\"\\n#RESCALE_CPR_SIM_FILE=$(ls -1 ${RESTART_FILE} | tail -1)\\n#RESCALE_CPR_ITERATION=$(ls -1 ${RESTART_FILE} | tail -1 | cut -f2 -d \\\"@\\\" | cut -f1 -d \\\".\\\" | sed 's/^0*//')\\n\\n### Start Rescale checkpoint restart processes\\nstart_rescale_checkpoint_restart\\n\\n### Application commands\\nif [[ -z \\\"${IS_RESTARTING}\\\" ]]; then\\necho \\\" -- Simulation from scratch\\\"\\n   starccm+ -power -batch run -load CpR_Reference_AutoSave.sim\\nelse\\n   echo \\\" -- Restarted from CpR file ${RESCALE_CPR_SIM_FILE} and iteration${RESCALE_CPR_ITERATION}\\\"\\n   mv CpR_Reference.sim CpR_Reference_Backup.sim\\n   mv ${RESCALE_CPR_SIM_FILE} CpR_Reference_AutoSave.sim\\n   starccm+ -power -batch run -load CpR_Reference_AutoSave.sim\\nfi\",\n",
      "      \"flags\": {\n",
      "        \"igCv\": true\n",
      "      },\n",
      "      \"hardware\": {\n",
      "        \"slots\": 1,\n",
      "        \"coresPerSlot\": 32,\n",
      "        \"coreType\": \"calcite\",\n",
      "        \"coreSummary\": {\n",
      "          \"numberOfNodes\": 1.0,\n",
      "          \"memoryPerNode\": 256000.0,\n",
      "          \"storagePerNode\": 2400,\n",
      "          \"gpusPerNode\": 0\n",
      "        },\n",
      "        \"walltime\": 10,\n",
      "        \"coreClass\": null,\n",
      "        \"type\": \"compute\",\n",
      "        \"scheduler\": {},\n",
      "        \"rceConnector\": {},\n",
      "        \"isReusable\": false\n",
      "      },\n",
      "      \"inputFolders\": [],\n",
      "      \"postProcessScript\": null,\n",
      "      \"postProcessScriptCommand\": \"\",\n",
      "      \"preProcessScript\": null,\n",
      "      \"preProcessScriptCommand\": \"\",\n",
      "      \"templateTasks\": [],\n",
      "      \"inputFiles\": []\n",
      "    }\n",
      "  ],\n",
      "  \"paramFile\": null,\n",
      "  \"caseFile\": null,\n",
      "  \"jobvariables\": [],\n",
      "  \"isTemplateDryRun\": false,\n",
      "  \"includeNominalRun\": false,\n",
      "  \"monteCarloIterations\": null,\n",
      "  \"expectedRuns\": null,\n",
      "  \"remoteVizConfig\": null,\n",
      "  \"attachedJobs\": [],\n",
      "  \"projectId\": \"BKuia\",\n",
      "  \"cluster\": null,\n",
      "  \"autoTerminateCluster\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(\n",
    "    'https://kr.rescale.com/api/v2/jobs/' + 'qCJPd',\n",
    "    # 'https://kr.rescale.com/api/v2/jobs/<Job ID>\n",
    "    headers = {'Authorization': 'Token ' + apikey}\n",
    ")\n",
    "\n",
    "req_dict = json.loads(req.text)\n",
    "data = json.dumps(req_dict, indent=2)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b23d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0bf221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
